{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43f07e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    This file is part of PM4Py (More Info: https://pm4py.fit.fraunhofer.de).\n",
    "\n",
    "    PM4Py is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "\n",
    "    PM4Py is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with PM4Py.  If not, see <https://www.gnu.org/licenses/>.\n",
    "'''\n",
    "from pm4py.objects import log as log_lib\n",
    "from pm4py.algo.evaluation.precision import utils as precision_utils\n",
    "from pm4py.objects.petri_net.utils import align_utils as utils, check_soundness\n",
    "from pm4py.objects.petri_net.obj import Marking\n",
    "from pm4py.objects.petri_net.utils.petri_utils import construct_trace_net\n",
    "from pm4py.objects.petri_net.utils.synchronous_product import construct\n",
    "from pm4py.statistics.start_activities.log.get import get_start_activities\n",
    "from pm4py.objects.petri_net.utils.align_utils import get_visible_transitions_eventually_enabled_by_marking\n",
    "from pm4py.util import exec_utils\n",
    "from pm4py.util import xes_constants\n",
    "import pkgutil\n",
    "from enum import Enum\n",
    "from pm4py.util import constants\n",
    "from typing import Optional, Dict, Any, Union, Tuple\n",
    "from pm4py.objects.log.obj import EventLog, EventStream\n",
    "from pm4py.objects.petri_net.obj import PetriNet, Marking\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Parameters(Enum):\n",
    "    ACTIVITY_KEY = constants.PARAMETER_CONSTANT_ACTIVITY_KEY\n",
    "    TOKEN_REPLAY_VARIANT = \"token_replay_variant\"\n",
    "    CLEANING_TOKEN_FLOOD = \"cleaning_token_flood\"\n",
    "    SHOW_PROGRESS_BAR = \"show_progress_bar\"\n",
    "    MULTIPROCESSING = \"multiprocessing\"\n",
    "    CORES = \"cores\"\n",
    "\n",
    "\n",
    "\n",
    "def apply(log: Union[EventLog, EventStream, pd.DataFrame], net: PetriNet, marking: Marking, final_marking: Marking, parameters: Optional[Dict[Union[str, Parameters], Any]] = None) -> float:\n",
    "    \"\"\"\n",
    "    Get Align-ET Conformance precision\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    log\n",
    "        Trace log\n",
    "    net\n",
    "        Petri net\n",
    "    marking\n",
    "        Initial marking\n",
    "    final_marking\n",
    "        Final marking\n",
    "    parameters\n",
    "        Parameters of the algorithm, including:\n",
    "            Parameters.ACTIVITY_KEY -> Activity key\n",
    "    \"\"\"\n",
    "\n",
    "    if parameters is None:\n",
    "        parameters = {}\n",
    "\n",
    "    debug_level = parameters[\"debug_level\"] if \"debug_level\" in parameters else 0\n",
    "\n",
    "    activity_key = exec_utils.get_param_value(Parameters.ACTIVITY_KEY, parameters, log_lib.util.xes.DEFAULT_NAME_KEY)\n",
    "\n",
    "    # default value for precision, when no activated transitions (not even by looking at the initial marking) are found\n",
    "    precision = 1.0\n",
    "    sum_ee = 0\n",
    "    sum_at = 0\n",
    "    unfit = 0\n",
    "\n",
    "    if not check_soundness.check_easy_soundness_net_in_fin_marking(net, marking, final_marking):\n",
    "        raise Exception(\"trying to apply Align-ETConformance on a Petri net that is not a easy sound net!!\")\n",
    "\n",
    "    prefixes, prefix_count = precision_utils.get_log_prefixes(log, activity_key=activity_key)\n",
    "    prefixes_keys = list(prefixes.keys())\n",
    "    fake_log = precision_utils.form_fake_log(prefixes_keys, activity_key=activity_key)\n",
    "\n",
    "    align_stop_marking = align_fake_log_stop_marking(fake_log, net, marking, final_marking, parameters=parameters)\n",
    "    \n",
    "    all_markings = transform_markings_from_sync_to_original_net(align_stop_marking, net, parameters=parameters)\n",
    "\n",
    "    for i in range(len(prefixes)):\n",
    "        markings = all_markings[i]\n",
    "\n",
    "        if markings is not None:\n",
    "            log_transitions = set(prefixes[prefixes_keys[i]])\n",
    "            activated_transitions_labels = set()\n",
    "            for m in markings:\n",
    "                # add to the set of activated transitions in the model the activated transitions\n",
    "                # for each prefix\n",
    "                activated_transitions_labels = activated_transitions_labels.union(\n",
    "                    x.label for x in utils.get_visible_transitions_eventually_enabled_by_marking(net, m) if\n",
    "                    x.label is not None)\n",
    "            escaping_edges = activated_transitions_labels.difference(log_transitions)\n",
    "\n",
    "            sum_at += len(activated_transitions_labels) * prefix_count[prefixes_keys[i]]\n",
    "            sum_ee += len(escaping_edges) * prefix_count[prefixes_keys[i]]\n",
    "\n",
    "            if debug_level > 1:\n",
    "                print(\"\")\n",
    "                print(\"prefix=\", prefixes_keys[i])\n",
    "                print(\"log_transitions=\", log_transitions)\n",
    "                print(\"activated_transitions=\", activated_transitions_labels)\n",
    "                print(\"escaping_edges=\", escaping_edges)\n",
    "        else:\n",
    "            unfit += prefix_count[prefixes_keys[i]]\n",
    "\n",
    "    if debug_level > 0:\n",
    "        print(\"\\n\")\n",
    "        print(\"overall unfit\", unfit)\n",
    "        print(\"overall activated transitions\", sum_at)\n",
    "        print(\"overall escaping edges\", sum_ee)\n",
    "\n",
    "    # fix: also the empty prefix should be counted!\n",
    "    start_activities = set(get_start_activities(log, parameters=parameters))\n",
    "    trans_en_ini_marking = set([x.label for x in get_visible_transitions_eventually_enabled_by_marking(net, marking)])\n",
    "    diff = trans_en_ini_marking.difference(start_activities)\n",
    "    sum_at += len(log) * len(trans_en_ini_marking)\n",
    "    sum_ee += len(log) * len(diff)\n",
    "    # end fix\n",
    "\n",
    "    if sum_at > 0:\n",
    "        precision = 1 - float(sum_ee) / float(sum_at)\n",
    "    \n",
    "    return precision\n",
    "\n",
    "def transform_markings_from_sync_to_original_net(markings0, net, parameters=None):\n",
    "    \"\"\"\n",
    "    Transform the markings of the sync net (in which alignment stops) into markings of the original net\n",
    "    (in order to measure the precision)\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    markings0\n",
    "        Markings on the sync net (expressed as place name with count)\n",
    "    net\n",
    "        Petri net\n",
    "    parameters\n",
    "        Parameters of the algorithm\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    markings\n",
    "        Markings of the original model (expressed as place with count)\n",
    "    \"\"\"\n",
    "    if parameters is None:\n",
    "        parameters = {}\n",
    "\n",
    "    places_corr = {p.name: p for p in net.places}\n",
    "\n",
    "    markings = []\n",
    "\n",
    "    for i in range(len(markings0)):\n",
    "        res_list = markings0[i]\n",
    "\n",
    "        # res_list shall be a list of markings.\n",
    "        # If it is None, then there is no correspondence markings\n",
    "        # in the original Petri net\n",
    "        if res_list is not None:\n",
    "            # saves all the markings reached by the optimal alignment\n",
    "            # as markings of the original net\n",
    "            markings.append([])\n",
    "\n",
    "            for j in range(len(res_list)):\n",
    "                res = res_list[j]\n",
    "\n",
    "                atm = Marking()\n",
    "                for pl, count in res.items():\n",
    "                    if pl[0] == utils.SKIP:\n",
    "                        atm[places_corr[pl[1]]] = count\n",
    "                markings[-1].append(atm)\n",
    "        else:\n",
    "            markings.append(None)\n",
    "\n",
    "    return markings\n",
    "\n",
    "\n",
    "\n",
    "def align_fake_log_stop_marking(fake_log, net, marking, final_marking, parameters=None):\n",
    "    \"\"\"\n",
    "    Align the 'fake' log with all the prefixes in order to get the markings in which\n",
    "    the alignment stops\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    fake_log\n",
    "        Fake log\n",
    "    net\n",
    "        Petri net\n",
    "    marking\n",
    "        Marking\n",
    "    final_marking\n",
    "        Final marking\n",
    "    parameters\n",
    "        Parameters of the algorithm\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    alignment\n",
    "        For each trace in the log, return the marking in which the alignment stops (expressed as place name with count)\n",
    "    \"\"\"\n",
    "    if parameters is None:\n",
    "        parameters = {}\n",
    "\n",
    "    show_progress_bar = exec_utils.get_param_value(Parameters.SHOW_PROGRESS_BAR, parameters, True)\n",
    "    multiprocessing = exec_utils.get_param_value(Parameters.MULTIPROCESSING, parameters, False)\n",
    "\n",
    "    progress = None\n",
    "    if pkgutil.find_loader(\"tqdm\") and show_progress_bar and len(fake_log) > 1:\n",
    "        from tqdm.auto import tqdm\n",
    "        progress = tqdm(total=len(fake_log), desc=\"computing precision with alignments, completed variants :: \")\n",
    "\n",
    "    if multiprocessing:\n",
    "        align_intermediate_result = __align_log_with_multiprocessing_stop_marking(fake_log, net, marking, final_marking,\n",
    "                                                                                progress, parameters=parameters)\n",
    "    else:\n",
    "        align_intermediate_result = __align_log_wo_multiprocessing_stop_marking(fake_log, net, marking, final_marking,\n",
    "                                                                                progress, parameters=parameters)\n",
    "\n",
    "    align_result = []\n",
    "    for i in range(len(align_intermediate_result)):\n",
    "        res = align_intermediate_result[i]\n",
    "        if res is not None:\n",
    "            align_result.append([])\n",
    "            for mark in res:\n",
    "                res2 = {}\n",
    "                for pl in mark:\n",
    "                    # transforms the markings for easier correspondence at the end\n",
    "                    # (distributed engine friendly!)\n",
    "                    res2[(pl.name[0], pl.name[1])] = mark[pl]\n",
    "\n",
    "                align_result[-1].append(res2)\n",
    "        else:\n",
    "            # if there is no path from the initial marking\n",
    "            # replaying the given prefix, then add None\n",
    "            align_result.append(None)\n",
    "\n",
    "    # gracefully close progress bar\n",
    "    if progress is not None:\n",
    "        progress.close()\n",
    "    del progress\n",
    "\n",
    "    return align_result\n",
    "\n",
    "\n",
    "\n",
    "def __align_log_wo_multiprocessing_stop_marking(fake_log, net, marking, final_marking, progress, parameters=None):\n",
    "    align_intermediate_result = []\n",
    "    for i in range(len(fake_log)):\n",
    "        res = __align_trace_stop_marking(fake_log[i], net, marking, final_marking, parameters=parameters)\n",
    "        align_intermediate_result.append(res)\n",
    "        if progress is not None:\n",
    "            progress.update()\n",
    "\n",
    "    return align_intermediate_result\n",
    "\n",
    "\n",
    "def __align_log_with_multiprocessing_stop_marking(fake_log, net, marking, final_marking, progress, parameters=None):\n",
    "    if parameters is not None:\n",
    "        parameters = {}\n",
    "\n",
    "    import multiprocessing\n",
    "    from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "    num_cores = exec_utils.get_param_value(Parameters.CORES, parameters, multiprocessing.cpu_count() - 2)\n",
    "    align_intermediate_result = []\n",
    "    with ProcessPoolExecutor(max_workers=num_cores) as executor:\n",
    "        futures = []\n",
    "        for i in range(len(fake_log)):\n",
    "            futures.append(executor.submit(__align_trace_stop_marking, fake_log[i], net, marking, final_marking, parameters))\n",
    "        if progress is not None:\n",
    "            alignments_ready = 0\n",
    "            while alignments_ready != len(futures):\n",
    "                current = 0\n",
    "                for index, variant in enumerate(futures):\n",
    "                    current = current + 1 if futures[index].done() else current\n",
    "                if current > alignments_ready:\n",
    "                    for i in range(0, current - alignments_ready):\n",
    "                        progress.update()\n",
    "                alignments_ready = current\n",
    "        for index, variant in enumerate(futures):\n",
    "            align_intermediate_result.append(futures[index].result())\n",
    "\n",
    "    return align_intermediate_result\n",
    "\n",
    "\n",
    "def __align_trace_stop_marking(trace, net, marking, final_marking, parameters=None):\n",
    "    sync_net, sync_initial_marking, sync_final_marking = build_sync_net(trace, net, marking, final_marking,\n",
    "                                                                        parameters=parameters)\n",
    "    stop_marking = Marking()\n",
    "    for pl, count in sync_final_marking.items():\n",
    "        if pl.name[1] == utils.SKIP:\n",
    "            stop_marking[pl] = count\n",
    "    cost_function = utils.construct_standard_cost_function(sync_net, utils.SKIP)\n",
    "\n",
    "    # perform the alignment of the prefix\n",
    "    res = precision_utils.__search(sync_net, sync_initial_marking, sync_final_marking, stop_marking, cost_function,\n",
    "                                   utils.SKIP)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def build_sync_net(trace, petri_net, initial_marking, final_marking, parameters=None):\n",
    "    \"\"\"\n",
    "    Build the sync product net between the Petri net and the trace prefix\n",
    "\n",
    "    Parameters\n",
    "    ---------------\n",
    "    trace\n",
    "        Trace prefix\n",
    "    petri_net\n",
    "        Petri net\n",
    "    initial_marking\n",
    "        Initial marking\n",
    "    final_marking\n",
    "        Final marking\n",
    "    parameters\n",
    "        Possible parameters of the algorithm\n",
    "    \"\"\"\n",
    "    if parameters is None:\n",
    "        parameters = {}\n",
    "\n",
    "    activity_key = exec_utils.get_param_value(Parameters.ACTIVITY_KEY, parameters, xes_constants.DEFAULT_NAME_KEY)\n",
    "\n",
    "    trace_net, trace_im, trace_fm = construct_trace_net(trace, activity_key=activity_key)\n",
    "\n",
    "    sync_prod, sync_initial_marking, sync_final_marking = construct(trace_net, trace_im,\n",
    "                                                                                              trace_fm, petri_net,\n",
    "                                                                                              initial_marking,\n",
    "                                                                                              final_marking,\n",
    "                                                                                              utils.SKIP)\n",
    "\n",
    "    return sync_prod, sync_initial_marking, sync_final_marking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67544d1a",
   "metadata": {},
   "source": [
    "# Precision Contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1d16dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_partitioned(log: Union[EventLog, EventStream, pd.DataFrame], net: PetriNet, marking: Marking, final_marking: Marking, parameters: Optional[Dict[Union[str, Parameters], Any]] = None) -> float:\n",
    "    \"\"\"\n",
    "    Get Align-ET Conformance precision\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    log\n",
    "        Trace log\n",
    "    net\n",
    "        Petri net\n",
    "    marking\n",
    "        Initial marking\n",
    "    final_marking\n",
    "        Final marking\n",
    "    parameters\n",
    "        Parameters of the algorithm, including:\n",
    "            Parameters.ACTIVITY_KEY -> Activity key\n",
    "    \"\"\"\n",
    "\n",
    "    if parameters is None:\n",
    "        parameters = {}\n",
    "\n",
    "    debug_level = parameters[\"debug_level\"] if \"debug_level\" in parameters else 0\n",
    "\n",
    "    activity_key = exec_utils.get_param_value(Parameters.ACTIVITY_KEY, parameters, log_lib.util.xes.DEFAULT_NAME_KEY)\n",
    "\n",
    "    # default value for precision, when no activated transitions (not even by looking at the initial marking) are found\n",
    "    precision = 1.0\n",
    "    sum_ee = 0\n",
    "    sum_at = 0\n",
    "    unfit = 0\n",
    "\n",
    "    if not check_soundness.check_easy_soundness_net_in_fin_marking(net, marking, final_marking):\n",
    "        raise Exception(\"trying to apply Align-ETConformance on a Petri net that is not a easy sound net!!\")\n",
    "\n",
    "    prefixes, prefix_count = precision_utils.get_log_prefixes(log, activity_key=activity_key)\n",
    "    prefixes_keys = list(prefixes.keys())\n",
    "\n",
    "    return {\n",
    "        \"prefixes\": prefixes,\n",
    "        \"prefixes_keys\": prefixes_keys,\n",
    "        \"prefix_count\": prefix_count,\n",
    "        \"all_markings\": all_markings\n",
    "    }\n",
    "    \n",
    "def get_precision_total(prefixes, prefixes_keys, prefix_count, net, log, marking, parameters = {}):\n",
    "    \n",
    "    precision = 1.0\n",
    "    sum_ee = 0\n",
    "    sum_at = 0\n",
    "    unfit = 0\n",
    "    \n",
    "    fake_log = precision_utils.form_fake_log(all_prefixes_keys)\n",
    "    align_stop_marking = align_fake_log_stop_marking(fake_log, net, im, fm)\n",
    "    all_markings = transform_markings_from_sync_to_original_net(align_stop_marking, net)\n",
    "    \n",
    "    for i in range(len(prefixes)):\n",
    "        markings = all_markings[i]\n",
    "\n",
    "        if markings is not None:\n",
    "            log_transitions = set(prefixes[prefixes_keys[i]])\n",
    "            activated_transitions_labels = set()\n",
    "            for m in markings:\n",
    "                # add to the set of activated transitions in the model the activated transitions\n",
    "                # for each prefix\n",
    "                activated_transitions_labels = activated_transitions_labels.union(\n",
    "                    x.label for x in utils.get_visible_transitions_eventually_enabled_by_marking(net, m) if\n",
    "                    x.label is not None)\n",
    "            escaping_edges = activated_transitions_labels.difference(log_transitions)\n",
    "\n",
    "            sum_at += len(activated_transitions_labels) * prefix_count[prefixes_keys[i]]\n",
    "            sum_ee += len(escaping_edges) * prefix_count[prefixes_keys[i]]\n",
    "\n",
    "        else:\n",
    "            unfit += prefix_count[prefixes_keys[i]]\n",
    "\n",
    "    # fix: also the empty prefix should be counted!\n",
    "    start_activities = set(get_start_activities(log, parameters=parameters))\n",
    "    trans_en_ini_marking = set([x.label for x in get_visible_transitions_eventually_enabled_by_marking(net, marking)])\n",
    "    diff = trans_en_ini_marking.difference(start_activities)\n",
    "    sum_at += len(log) * len(trans_en_ini_marking)\n",
    "    sum_ee += len(log) * len(diff)\n",
    "    # end fix\n",
    "\n",
    "    if sum_at > 0:\n",
    "        precision = 1 - float(sum_ee) / float(sum_at)\n",
    "\n",
    "    return precision\n",
    "\n",
    "\n",
    "\n",
    "def unionPrefixes(prefixes):\n",
    "    result = {}\n",
    "    for prefix in prefixes:\n",
    "        for key, value in prefix.items():\n",
    "            if key in result:\n",
    "                result[key] = set().union(result[key], value)\n",
    "            else:\n",
    "                result[key] = value\n",
    "    return result\n",
    "\n",
    "# def precision_aggregator(precisions):\n",
    "#     all_prefixes = {}\n",
    "#     all_prefixes = unionPrefixes([precision_alignments_0_40['prefixes'], precision_alignments_40_80['prefixes']])\n",
    "#     all_prefixes_keys = list(set(precision_alignments_0_40['prefixes_keys']).union(precision_alignments_40_80['prefixes_keys']))\n",
    "#     all_prefix_count = precision_alignments_0_40['prefix_count'] + precision_alignments_40_80['prefix_count']\n",
    "    \n",
    "#     precision_score = get_precision_total(\n",
    "#         prefixes = all_prefixes, \n",
    "#         prefixes_keys = all_prefixes_keys, \n",
    "#         prefix_count = all_prefix_count,\n",
    "#         net = net,\n",
    "#         log = dataframe,\n",
    "#         marking = im\n",
    "#     )\n",
    "    \n",
    "#     return precision_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53170072",
   "metadata": {},
   "source": [
    "# Fitness contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9672c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments\n",
    "from pm4py.algo.conformance.alignments.decomposed import algorithm as decomp_alignments\n",
    "from pm4py.util import exec_utils\n",
    "from enum import Enum\n",
    "from pm4py.util import constants\n",
    "from typing import Optional, Dict, Any, Union, Tuple, List\n",
    "from pm4py.objects.log.obj import EventLog, EventStream, Trace\n",
    "from pm4py.objects.petri_net.obj import PetriNet, Marking\n",
    "import pandas as pd\n",
    "from pm4py.util import typing\n",
    "\n",
    "def fitness_apply_partitioned(log: EventLog, petri_net: PetriNet, initial_marking: Marking, final_marking: Marking, align_variant=alignments.DEFAULT_VARIANT, parameters: Optional[Dict[Union[str, Parameters], Any]] = None) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate fitness based on alignments\n",
    "\n",
    "    Parameters\n",
    "    ----------------\n",
    "    log\n",
    "        Event log\n",
    "    petri_net\n",
    "        Petri net\n",
    "    initial_marking\n",
    "        Initial marking\n",
    "    final_marking\n",
    "        Final marking\n",
    "    align_variant\n",
    "        Variants of the alignments to apply\n",
    "    parameters\n",
    "        Parameters of the algorithm\n",
    "\n",
    "    Returns\n",
    "    ---------------\n",
    "    dictionary\n",
    "        Containing two keys (percFitTraces and averageFitness)\n",
    "    \"\"\"\n",
    "    if parameters is None:\n",
    "        parameters = {}\n",
    "\n",
    "    multiprocessing = exec_utils.get_param_value(Parameters.MULTIPROCESSING, parameters, False)\n",
    "\n",
    "    if align_variant == decomp_alignments.Variants.RECOMPOS_MAXIMAL.value:\n",
    "        alignment_result = decomp_alignments.apply(log, petri_net, initial_marking, final_marking,\n",
    "                                                   variant=align_variant, parameters=parameters)\n",
    "    else:\n",
    "        if multiprocessing:\n",
    "            alignment_result = alignments.apply_multiprocessing(log, petri_net, initial_marking, final_marking, variant=align_variant,\n",
    "                                                parameters=parameters)\n",
    "        else:\n",
    "            alignment_result = alignments.apply(log, petri_net, initial_marking, final_marking, variant=align_variant,\n",
    "                                                parameters=parameters)\n",
    "    return alignment_result\n",
    "\n",
    "def evaluate_fitness(aligned_traces: typing.ListAlignments, parameters: Optional[Dict[Union[str, Parameters], Any]] = None) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Transforms the alignment result to a simple dictionary\n",
    "    including the percentage of fit traces and the average fitness\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    aligned_traces\n",
    "        Alignments calculated for the traces in the log\n",
    "    parameters\n",
    "        Possible parameters of the evaluation\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    dictionary\n",
    "        Containing two keys (percFitTraces and averageFitness)\n",
    "    \"\"\"\n",
    "    if parameters is None:\n",
    "        parameters = {}\n",
    "    str(parameters)\n",
    "    no_traces = len([x for x in aligned_traces if x is not None])\n",
    "    no_fit_traces = 0\n",
    "    sum_fitness = 0.0\n",
    "    sum_bwc = 0.0\n",
    "    sum_cost = 0.0\n",
    "\n",
    "    for tr in aligned_traces:\n",
    "        if tr is not None:\n",
    "            if tr[\"fitness\"] == 1.0:\n",
    "                no_fit_traces = no_fit_traces + 1\n",
    "            sum_fitness += tr[\"fitness\"]\n",
    "            sum_bwc += tr[\"bwc\"]\n",
    "            sum_cost += tr[\"cost\"]\n",
    "\n",
    "    perc_fit_traces = 0.0\n",
    "    average_fitness = 0.0\n",
    "    log_fitness = 0.0\n",
    "\n",
    "    if no_traces > 0:\n",
    "        perc_fit_traces = (100.0 * float(no_fit_traces)) / (float(no_traces))\n",
    "        average_fitness = float(sum_fitness) / float(no_traces)\n",
    "        log_fitness = 1.0 - float(sum_cost) / float(sum_bwc)\n",
    "\n",
    "    return {\"percFitTraces\": perc_fit_traces, \"averageFitness\": average_fitness,\n",
    "            \"percentage_of_fitting_traces\": perc_fit_traces,\n",
    "            \"average_trace_fitness\": average_fitness, \"log_fitness\": log_fitness}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8db82a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importers\n",
    "from pm4py import convert_to_event_log, convert_to_dataframe, format_dataframe\n",
    "\n",
    "# Miners\n",
    "from pm4py import serialize, deserialize\n",
    "from pm4py import discover_dfg as dfg_discovery\n",
    "\n",
    "from pm4py.algo.discovery.alpha import algorithm as alpha_miner\n",
    "from pm4py.algo.discovery.heuristics import algorithm as heuristics_miner\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "\n",
    "\n",
    "# Evaluators\n",
    "from pm4py.algo.evaluation.simplicity import algorithm as simplicity_evaluator\n",
    "from pm4py.algo.evaluation.replay_fitness import algorithm as replay_fitness_evaluator\n",
    "from pm4py.algo.evaluation.precision import algorithm as precision_evaluator\n",
    "from pm4py.algo.evaluation.generalization import algorithm as generalization_evaluator\n",
    "import pandas as pd\n",
    "import re\n",
    "import pm4py\n",
    "from pm4py.discovery import DFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a2ba7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py import discover_dfg_typed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9da59736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57/3723482806.py:1: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('BPIC15_1.csv')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('BPIC15_1.csv')\n",
    "# log = pm4py.read_xes('BPI Challenge 2017.xes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a3ccd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = data['case:concept:name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "813c6341",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = data[data['case:concept:name'].isin(groups[0:40])][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "466eb17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe.groupby('case:concept:name')['case:concept:name'].count().describe() # :80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e2d325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['time:timestamp'] = pd.to_datetime(dataframe['time:timestamp'], utc=True)\n",
    "dataframe['concept:name'] = dataframe['concept:name'].astype(str)\n",
    "dataframe['case:concept:name'] = dataframe['case:concept:name'].astype(str)\n",
    "\n",
    "# data['time:timestamp'] = pd.to_datetime(data['time:timestamp'], utc=True)\n",
    "# data['concept:name'] = data['concept:name'].astype(str)\n",
    "# data['case:concept:name'] = data['case:concept:name'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9e6762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg, start_activities, end_activities = dfg_discovery(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6137ddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "theDfg = DFG(dfg, start_activities=start_activities, end_activities=end_activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c3557e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net, im, fm = pm4py.discover_petri_net_inductive(theDfg, activity_key='concept:name', case_id_key='case:concept:name', timestamp_key='time:timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8185d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision_alignments_0_80_value = apply(dataframe, net, im, fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1d88127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff7d79f70284c2bbc7da82d1676b246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fitness_alignments_0_40 = fitness_apply_partitioned(dataframe, net, im, fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313d412f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c314822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_fitness = fitness_alignments_0_40 + fitness_alignments_40_80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c24bce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate_fitness(total_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32765d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_0_80 = evaluate_fitness(fitness_alignments_0_80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b33c383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'percFitTraces': 16.25,\n",
       " 'averageFitness': 0.9804238931790744,\n",
       " 'percentage_of_fitting_traces': 16.25,\n",
       " 'average_trace_fitness': 0.9804238931790744,\n",
       " 'log_fitness': 0.9831704402738571}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result # 0:40 + 40:80 (2 partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b22fbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'percFitTraces': 16.25,\n",
       " 'averageFitness': 0.9804238931790744,\n",
       " 'percentage_of_fitting_traces': 16.25,\n",
       " 'average_trace_fitness': 0.9804238931790744,\n",
       " 'log_fitness': 0.9831704402738571}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_0_80 # :80 (all data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
