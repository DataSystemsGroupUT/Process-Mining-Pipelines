{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0df7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.dataframe import from_pandas\n",
    "from dask.dataframe.utils import make_meta\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j.exceptions import ClientError\n",
    "from dask.distributed import Client, LocalCluster, get_worker\n",
    "import dask\n",
    "\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "import gc\n",
    "import numpy as np\n",
    "import dill\n",
    "\n",
    "# Miners\n",
    "from pm4py import serialize, deserialize\n",
    "from pm4py import discover_dfg as dfg_discovery\n",
    "from pm4py.discovery import DFG\n",
    "\n",
    "from pm4py.algo.discovery.alpha import algorithm as alpha_miner\n",
    "from pm4py.algo.discovery.heuristics import algorithm as heuristics_miner\n",
    "from pm4py import discover_petri_net_inductive as inductive_miner\n",
    "\n",
    "\n",
    "# Evaluators\n",
    "from contribution import fitness_alignment, generalization, precision_alignment\n",
    "from pm4py.algo.evaluation.simplicity import algorithm as simplicity_evaluator #simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cf08aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0xffffa428c910>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.config.set({'distributed.scheduler.active-memory-manager.start': True, 'distributed.worker.memory.spill': 0.60})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15189d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "158c668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ctypes\n",
    "\n",
    "# def trim_memory() -> int:\n",
    "#     libc = ctypes.CDLL(\"libc.so.6\")\n",
    "#     return libc.malloc_trim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc779c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class graph_driver():\n",
    "    def __init__(self, uri_scheme='bolt', host='localhost', port='7687', username='neo4j', password='123456'):\n",
    "        self.uri_scheme = uri_scheme\n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        \n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        \n",
    "        self.connection_uri = \"{uri_scheme}://{host}:{port}\".format(uri_scheme=self.uri_scheme, host=self.host, port=self.port)\n",
    "        self.auth = (self.username, self.password)\n",
    "        self.driver = GraphDatabase.driver(self.connection_uri, auth=self.auth)\n",
    "        \n",
    "    def __del__(self):\n",
    "        self._close_driver()\n",
    "    \n",
    "    def _close_driver(self):\n",
    "        if self.driver:\n",
    "            self.driver.close()\n",
    "    \n",
    "    def run_single_query(self, query):\n",
    "        res = None\n",
    "        with self.driver.session() as session:\n",
    "            raw_res = session.run(query)\n",
    "            res = self.format_raw_res(raw_res)\n",
    "        return res\n",
    "    \n",
    "    def run_bulk_query(self, query_list):\n",
    "        results = []\n",
    "        with self.driver.session() as session:\n",
    "            for query in tqdm(query_list):\n",
    "                raw_res = session.run(query)\n",
    "                res = self.format_raw_res(raw_res)\n",
    "                results.append({'query':query, 'result':res})\n",
    "        return results\n",
    "    \n",
    "    def reset_graph(self, db=None):\n",
    "        return self.run_single_query(\"MATCH (n) DETACH DELETE n\")\n",
    "    \n",
    "    def test_connection(self):\n",
    "        return self.run_single_query(\"MATCH (n) RETURN COUNT(n) as nodes\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def format_raw_res(raw_res):\n",
    "        res = []\n",
    "        for r in raw_res:\n",
    "            res.append(r)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10ede6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def useExecutionTime(func):\n",
    "    \n",
    "    def compute(*args, **kwargs):\n",
    "        begin = time.time()\n",
    "        \n",
    "        result = func(*args, **kwargs)\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        return {\"result\": result, \"execution_time\": end - begin}\n",
    " \n",
    "    return compute\n",
    "\n",
    "@useExecutionTime\n",
    "def getComputeTime(*args, **kwargs):\n",
    "    return dask.compute(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdd1a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster = LocalCluster(n_workers=1, threads_per_worker=1, memory_limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54b9bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = Client(cluster)\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af7e6d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gc(dask_worker,**kwargs):\n",
    "    gc.collect()\n",
    "    return True\n",
    "\n",
    "# Register the GC function as a plugin\n",
    "# client.register_worker_plugin(run_gc, \"my_gc_plugin\")\n",
    "# client.register_worker_plugin(trim_memory, \"my_trim_plugin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ba2b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster.adapt(minimum=1, maximum=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0ae56e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnTypes = {\n",
    "    'case:IDofConceptCase': 'string',\n",
    "    'case:Includes_subCases': 'string',\n",
    "    'case:Responsible_actor': 'string',\n",
    "    'case:caseProcedure': 'string',\n",
    "    'case:concept:name': 'int64',\n",
    "    'dueDate': 'string',\n",
    "    'case:termName': 'string',\n",
    "    'dateStop': 'string',\n",
    "    'case:endDate': 'object',\n",
    "    'case:endDatePlanned': 'object',\n",
    "    'case:parts': 'object'\n",
    "}\n",
    "\n",
    "# list of file paths to be loaded\n",
    "file_paths = ['BPIC15_1.csv']\n",
    "\n",
    "# load the first file as a Dask dataframe\n",
    "df = dd.read_csv(file_paths[0], dtype=columnTypes)\n",
    "\n",
    "# iterate over the remaining files\n",
    "for file_path in file_paths[1:]:\n",
    "    # usecols parameter to load only the columns that are present in both dataframes\n",
    "    df_temp = dd.read_csv(file_path)\n",
    "    # concatenate the dataframes along the rows\n",
    "    df = dd.concat([df, dd.read_csv(file_path, dtype=columnTypes)], interleave_partitions=True)\n",
    "\n",
    "# columnTypes = {\n",
    "#     'OfferID': 'string'\n",
    "# }\n",
    "\n",
    "# fileName = 'BPI Challenge 2017'\n",
    "# df = dd.read_csv('{fileName}.csv'.format(fileName=fileName), dtype=columnTypes)\n",
    "for column in df.columns:\n",
    "    if re.search(\"[Dd]ate.*|time.*\", column):\n",
    "        df[column] = dask.dataframe.to_datetime(df[column], utc=True)\n",
    "        \n",
    "# df['case:concept:name'] = df['case:concept:name'].replace(to_replace=\"Application_\", value='', regex=True)\n",
    "df['case:concept:name'] = df['case:concept:name'].astype({'case:concept:name': 'int64'})\n",
    "        \n",
    "df = df.repartition(npartitions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "470c35e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformToDFG(dfgResult):\n",
    "    result = {}\n",
    "    for record in dfgResult:\n",
    "        result[(record[\"parent\"], record[\"child\"])] = record[\"frequency\"]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def transformToStartEndActivity(activities):\n",
    "    result = {}\n",
    "    for record in activities:\n",
    "        result[record['name']] = record[\"frequency\"]\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08471450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDFG():\n",
    "    queries = {\n",
    "        \"dfgQuery\": \"\"\"MATCH result=(p:Activity)-[r:PRODUCES]->(c:Activity) RETURN p.name as parent, c.name as child, r.frequency as frequency\"\"\",\n",
    "        \"startEndActivitiesQuery\": [\"MATCH (a:StartActivity) RETURN a.name as name , a.frequency as frequency\", \"MATCH (a:EndActivity) RETURN a.name as name , a.frequency as frequency\"],\n",
    "    }\n",
    "    \n",
    "    neo4jConnection = graph_driver(uri_scheme=\"neo4j\",host=\"neo4j\", password=\"123456\")\n",
    "    \n",
    "    dfgResult = neo4jConnection.run_single_query(queries['dfgQuery'])\n",
    "    startEndActivitiesResult = neo4jConnection.run_bulk_query(queries['startEndActivitiesQuery'])\n",
    "    return [transformToDFG(dfgResult), transformToStartEndActivity(startEndActivitiesResult[0][\"result\"]), transformToStartEndActivity(startEndActivitiesResult[1][\"result\"])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa32b162",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df = df.set_index('case:concept:name', drop=False, sorted=True)\n",
    "indexed_df['case:concept:name'] = indexed_df['case:concept:name'].astype({'case:concept:name': 'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acc70730",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df.index = indexed_df.index.rename('caseId')\n",
    "indexed_df = indexed_df.repartition(npartitions=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c59ea71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 2/2 [00:00<00:00, 206.54it/s]\n"
     ]
    }
   ],
   "source": [
    "dfg, start, end = getDFG()\n",
    "dfgObj = DFG(dfg, start_activities=start, end_activities=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c1d07c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@useExecutionTime\n",
    "def getMinerResult(dfg, miner, threshold = 0.5):\n",
    "    result = {}\n",
    "    if miner == 'heuristic_miner':\n",
    "        net, im, fm = heuristics_miner.apply_dfg(dfg['dfg'], parameters={heuristics_miner.Variants.CLASSIC.value.Parameters.DEPENDENCY_THRESH: threshold})\n",
    "    elif miner == 'inductive_miner':\n",
    "        net, im, fm = inductive_miner(dfg['dfgObj'])\n",
    "    elif miner == 'alpha_miner':\n",
    "        net, im, fm = alpha_miner.apply_dfg(dfg['dfg'])\n",
    "    \n",
    "    result[miner] = serialize(net, im, fm)\n",
    "    \n",
    "    return result\n",
    "    \n",
    "def setLazyMiners(dfg):\n",
    "    lazyList = []\n",
    "    miners = [\n",
    "#         'heuristic_miner',\n",
    "        'inductive_miner',\n",
    "#         'alpha_miner'\n",
    "    ]\n",
    "    for miner in miners:\n",
    "        task = dask.delayed(getMinerResult)(dfg, miner)\n",
    "        lazyList.append(task)\n",
    "    \n",
    "    return lazyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "163ef81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@useExecutionTime\n",
    "def getMetrics(log, miner, metric, net, im, fm):\n",
    "    sys.setrecursionlimit(3000)\n",
    "    try:\n",
    "        result = {\n",
    "            miner: {\n",
    "                metric: 0\n",
    "            }\n",
    "        }\n",
    "        if metric == 'fitness':\n",
    "            result[miner][metric] = fitness_alignment.apply(log, net, im, fm)\n",
    "        elif metric == 'simplicity':\n",
    "            result[miner][metric] = simplicity_evaluator.apply(net)\n",
    "        elif metric == 'precision':\n",
    "            result[miner][metric] = precision_alignment.apply(log, net, im, fm)\n",
    "        elif metric == 'generalization':\n",
    "            result[miner][metric] = generalization.apply(log, net, im, fm)\n",
    "\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return {miner: {metric: {\"error\": e}}}\n",
    "\n",
    "def setLazyMetrics(log, miners):\n",
    "    lazyList = []\n",
    "    metrics = [\n",
    "        'fitness',\n",
    "        'simplicity',\n",
    "        'precision',\n",
    "        'generalization'\n",
    "    ]\n",
    "    \n",
    "    for metric in metrics:\n",
    "        for miner in miners:\n",
    "            algorithm = list(miner['result'].keys())[0]\n",
    "            net, im, fm = deserialize(miner['result'][algorithm])\n",
    "            task = getMetrics(log, algorithm, metric, net, im, fm)\n",
    "            lazyList.append(task)\n",
    "    \n",
    "    return lazyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26251e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazyMiners = setLazyMiners({\"dfgObj\": dfgObj, \"dfg\": dfg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f366c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazyMinersResults = dask.compute(*lazyMiners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90de9df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazyMetrics = setLazyMetrics(indexed_df, lazyMinersResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e332366",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def aggregate(partitions):\n",
    "    result = {}\n",
    "    for partition in partitions:\n",
    "        for output in partition:\n",
    "            miner = list(output['result'].keys())[0]\n",
    "            metric = list(output['result'][miner].keys())[0]\n",
    "            e_time = output['execution_time']\n",
    "            \n",
    "            result.setdefault(miner, {})\n",
    "            result[miner].setdefault(metric, None)\n",
    "            \n",
    "            if result[miner][metric] == None:\n",
    "                result[miner][metric] = output['result'][miner][metric]\n",
    "            \n",
    "            \n",
    "            if metric and metric == 'fitness':\n",
    "                result[miner][metric] = fitness_alignment.aggregate(output['result'][miner][metric], result[miner][metric])        \n",
    "            elif metric and metric == 'precision':\n",
    "                result[miner][metric] = precision_alignment.aggregate(output['result'][miner][metric], result[miner][metric])\n",
    "            elif metric and metric == 'generalization':\n",
    "                result[miner][metric] = generalization.aggregate([output['result'][miner][metric], result[miner][metric]])\n",
    "            \n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8f27745",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def compute_metrics(aggregatedMetrics, minersResults):\n",
    "    results = {}\n",
    "    \n",
    "    getMinerResultByMiner = lambda results, miner: [value for value in lazyMinersResults if list(value['result'].keys())[0] == miner].pop()\n",
    "    \n",
    "    for miner, metrics in aggregatedMetrics.items():\n",
    "        net, im, fm = deserialize(getMinerResultByMiner(minersResults, miner)['result'][miner])\n",
    "        for metricKey, metricValue in metrics.items():\n",
    "            results.setdefault(miner, {})\n",
    "            results[miner].setdefault(metricKey, None)\n",
    "            if metricKey and metricKey == 'fitness':\n",
    "                results[miner][metricKey] = dask.delayed(fitness_alignment.compute)(metricValue)\n",
    "            elif metricKey and metricKey == 'precision':\n",
    "                results[miner][metricKey] = dask.delayed(precision_alignment.compute)(**metricValue, net=net, im=im, fm=fm)\n",
    "            elif metricKey and metricKey == 'generalization':\n",
    "                results[miner][metricKey] = dask.delayed(generalization.compute)(**metricValue, net=net)\n",
    "            elif metricKey and metricKey == 'simplicity':\n",
    "                results[miner][metricKey] = dask.delayed(simplicity_evaluator.apply)(net)\n",
    "                \n",
    "    # loop over the delayed functions for each miner/metric\n",
    "    for miner, metrics in results.items():\n",
    "        for metricKey, metricValue in metrics.items():\n",
    "            results[miner][metricKey] = dask.compute(results[miner][metricKey])\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "649993ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_data = indexed_df.map_partitions(setLazyMetrics, lazyMinersResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1ce10c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_results = aggregate(mapped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcc71c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ar = aggregated_results.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eba0a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net, im, fm = deserialize(lazyMinersResults[0]['result']['inductive_miner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "756eefaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(ar['inductive_miner']['precision']['prefixes'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2930c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute(**ar['inductive_miner']['precision'], net=net, im=im, fm=fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73b141af",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = compute_metrics(aggregated_results, lazyMinersResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46175abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5c7cb8a0fa49cfa30fea3ae26724df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743abca2850949a0b63dc11a767d2ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/158 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e87dc13d62464e92363feed730ed95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c00596dc214fc89f901f3247daaabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4985cfe3cdf4d5192ddb0ca1a85a284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed variants ::   0%|          | 0/158 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e0b52a4723495dbacdc0075db2646d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed variants ::   0%|          | 0/181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c0d9388fab44b9a49e04717624a6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed variants ::   0%|          | 0/221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17d0ff5443c4a688e3ea3a141f5b55a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "replaying log with TBR, completed variants ::   0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 16m 57s\n"
     ]
    }
   ],
   "source": [
    "results = r.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cf305dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inductive_miner': {'fitness': ({'percFitTraces': 0.16375545851528384,\n",
       "    'averageFitness': 0.9700734087352779,\n",
       "    'percentage_of_fitting_traces': 0.16375545851528384,\n",
       "    'average_trace_fitness': 0.9700734087352779,\n",
       "    'log_fitness': 0.9773335485123311},),\n",
       "  'simplicity': (0.34338358458961477,),\n",
       "  'precision': (0.020420404099899092,),\n",
       "  'generalization': (-0.9268846002666846,)}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
