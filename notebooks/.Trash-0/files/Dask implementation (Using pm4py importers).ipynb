{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.dataframe import from_pandas\n",
    "from dask.dataframe.utils import make_meta\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j.exceptions import ClientError\n",
    "from dask.distributed import Client, LocalCluster, get_worker\n",
    "import dask\n",
    "\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#importers\n",
    "from pm4py import read_xes, convert_to_event_log, convert_to_dataframe\n",
    "\n",
    "# Miners\n",
    "from pm4py import discover_dfg_typed as dfg_discovery, serialize, deserialize\n",
    "from pm4py.algo.discovery.alpha import algorithm as alpha_miner\n",
    "from pm4py.algo.discovery.heuristics import algorithm as heuristics_miner\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "from pm4py.algo.discovery.correlation_mining import algorithm as correlation_miner\n",
    "from pm4py.algo.discovery.temporal_profile import algorithm as temporal_profile_discovery\n",
    "\n",
    "\n",
    "# Evaluators\n",
    "from pm4py.algo.evaluation.simplicity import algorithm as simplicity_evaluator\n",
    "from pm4py.algo.evaluation.replay_fitness import algorithm as replay_fitness_evaluator\n",
    "from pm4py.algo.evaluation.precision import algorithm as precision_evaluator\n",
    "from pm4py.algo.evaluation.generalization import algorithm as generalization_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15189d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc779c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class graph_driver():\n",
    "    def __init__(self, uri_scheme='bolt', host='localhost', port='7687', username='neo4j', password='123456'):\n",
    "        self.uri_scheme = uri_scheme\n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        \n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        \n",
    "        self.connection_uri = \"{uri_scheme}://{host}:{port}\".format(uri_scheme=self.uri_scheme, host=self.host, port=self.port)\n",
    "        self.auth = (self.username, self.password)\n",
    "        self.driver = GraphDatabase.driver(self.connection_uri, auth=self.auth)\n",
    "        \n",
    "    def __del__(self):\n",
    "        self._close_driver()\n",
    "    \n",
    "    def _close_driver(self):\n",
    "        if self.driver:\n",
    "            self.driver.close()\n",
    "    \n",
    "    def run_single_query(self, query):\n",
    "        res = None\n",
    "        with self.driver.session() as session:\n",
    "            raw_res = session.run(query)\n",
    "            res = self.format_raw_res(raw_res)\n",
    "        return res\n",
    "    \n",
    "    def run_bulk_query(self, query_list):\n",
    "        results = []\n",
    "        with self.driver.session() as session:\n",
    "            for query in tqdm(query_list):\n",
    "                raw_res = session.run(query)\n",
    "                res = self.format_raw_res(raw_res)\n",
    "                results.append({'query':query, 'result':res})\n",
    "        return results\n",
    "    \n",
    "    def reset_graph(self, db=None):\n",
    "        return self.run_single_query(\"MATCH (n) DETACH DELETE n\")\n",
    "    \n",
    "    def test_connection(self):\n",
    "        return self.run_single_query(\"MATCH (n) RETURN COUNT(n) as nodes\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def format_raw_res(raw_res):\n",
    "        res = []\n",
    "        for r in raw_res:\n",
    "            res.append(r)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f196cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd1a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=4, threads_per_worker=8)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804704a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = from_pandas(convert_to_dataframe(read_xes('BPIC15_1.xes')), npartitions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba1cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(npartitions=4).set_index('case:concept:name', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a23cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df.index.rename(\"caseId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17748d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDFGQueries(dfg):\n",
    "    listOfQueries = []\n",
    "    queryTemplate = \"\"\"\n",
    "        MERGE (p:Activity {{name: '{parent}'}})\n",
    "        MERGE (c:Activity {{name: '{child}'}})\n",
    "        MERGE (p)-[r:PRODUCES]->(c)\n",
    "        ON CREATE SET r.frequency={frequency}\n",
    "        ON MATCH SET r.frequency=r.frequency+{frequency}\n",
    "    \"\"\"\n",
    "    for parent, child in dfg:\n",
    "        frequency = dfg[(parent, child)]\n",
    "        template = queryTemplate.format(parent=parent, child=child, frequency=frequency)\n",
    "        listOfQueries.append(template)\n",
    "    return listOfQueries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad96a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveDFG(dfg):\n",
    "    dfgResult = dfg_discovery(dfg)\n",
    "    dfgQuery = getDFGQueries(dfgResult.graph)\n",
    "    neo4jConnection = graph_driver(uri_scheme=\"neo4j\",host=\"neo4j\", password=\"123456\")\n",
    "    result = neo4jConnection.run_bulk_query(dfgQuery)\n",
    "    return dfgResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a963b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "paritionedLazyDFG = df.map_partitions(saveDFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1345fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test = dask.compute(paritionedLazyDFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82528ca2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfg_output = dask.compute(lazyDFG)[0] # hosted locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d07c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMinerResult(dfg, miner, threshold = 0.5):\n",
    "    result = {}\n",
    "    if miner == 'heuristic_miner':\n",
    "        net, im, fm = heuristics_miner.apply_dfg(dfg, parameters={heuristics_miner.Variants.CLASSIC.value.Parameters.DEPENDENCY_THRESH: threshold})\n",
    "    elif miner == 'inductive_miner':\n",
    "        net, im, fm = inductive_miner.apply_dfg(dfg, noise_threshold=0.9, multi_processing=True)\n",
    "    elif miner == 'alpha_miner':\n",
    "        net, im, fm = alpha_miner.apply_dfg(dfg)\n",
    "    \n",
    "    result[miner] = serialize(net, im, fm)\n",
    "    return result\n",
    "    \n",
    "def setLazyMiners(dfg):\n",
    "    lazyList = []\n",
    "    miners = [\n",
    "        'heuristic_miner', \n",
    "#         'inductive_miner',\n",
    "#         'alpha_miner'\n",
    "    ]\n",
    "    for miner in miners:\n",
    "        task = dask.delayed(getMinerResult)(dfg, miner)\n",
    "        lazyList.append(task)\n",
    "    \n",
    "    return lazyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163ef81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetrics(metric, log, petrinet, im, fm):\n",
    "    result = {}\n",
    "    if metric == 'fitness':\n",
    "        result[metric] = replay_fitness_evaluator.apply(log, petrinet, im, fm, variant=replay_fitness_evaluator.TOKEN_BASED)\n",
    "    elif metric == 'simplicity':\n",
    "        result[metric] = simplicity_evaluator.apply(petrinet)\n",
    "    elif metric == 'precision':\n",
    "        result[metric] = precision_evaluator.apply(log, petrinet, im, fm, variant=precision_evaluator.Variants.ETCONFORMANCE_TOKEN)\n",
    "    elif metric == 'generalization':\n",
    "        result[metric] = generalization_evaluator.apply(log, petrinet, im, fm)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def setLazyMetrics(dfg, petrinet, im, fm):\n",
    "    lazyList = []\n",
    "    metrics = [\n",
    "        'fitness', \n",
    "#         'simplicity', \n",
    "#         'precision', \n",
    "#         'generalization'\n",
    "    ]\n",
    "    \n",
    "    for metric in metrics:\n",
    "        task = dask.delayed(getMetrics)(metric, dfg, petrinet, im, fm)\n",
    "        lazyList.append(task)\n",
    "    \n",
    "    return lazyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26251e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazyMiners = setLazyMiners(dfg_output.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56dea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazyMiners[0].visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d0d714",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lazyMinersResults = dask.compute(*lazyMiners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193040b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net, im, fm = deserialize(lazyMinersResults[0]['heuristic_miner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90de9df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazyMetrics = setLazyMetrics(df, net, im, fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6683eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazyMetricsResults = dask.compute(*lazyMetrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
